from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from models import model_main as mm
from database.db import SessionLocal
from models.db_models import Product
import numpy as np
from numpy.linalg import norm
from openai import AsyncOpenAI
import json, asyncio
from datetime import datetime
import os

# -------------------------------------------------
with open("prompt.json", "r", encoding="utf-8") as f:
    prompt = json.load(f)

LOG_FILE = "chat_log.json"

# Ä°lk baÅŸta dosya yoksa oluÅŸtur
if not os.path.exists(LOG_FILE):
    with open(LOG_FILE, "w", encoding="utf-8") as f:
        json.dump({}, f)

router = APIRouter()
client = AsyncOpenAI()

class ChatRequest(BaseModel):
    message: str
    client_id: str

class ChatResponse(BaseModel):
    reply: str

def cosine(a: np.ndarray, b: np.ndarray) -> float:
    return float(np.dot(a, b) / (norm(a) * norm(b)))

# -------------------------------------------------
@router.post("/chat", response_model=ChatResponse)
async def chat_handler(payload: ChatRequest):
    try:
        req_msg   = payload.message.strip()
        client_id = payload.client_id.strip()

        # --- Log dosyasÄ±nÄ± oku
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            chat_log = json.load(f)

        # KullanÄ±cÄ± ilk defa geliyorsa messages ve state alanlarÄ±nÄ± oluÅŸtur
        if client_id not in chat_log:
            chat_log[client_id] = {
                "messages": {},
                "state": {
                    "ad": None,
                    "son_intent": None,
                    "son_urun": None,
                    "sorun_durumu": None,
                    "ozel_not": None
                }
            }

        # EÄŸer eski veride sadece messages varsa, state'i sonradan da ekleyelim (geriye dÃ¶nÃ¼k uyumluluk)
        elif "state" not in chat_log[client_id]:
            chat_log[client_id]["state"] = {
                "ad": None,
                "son_intent": None,
                "son_urun": None,
                "sorun_durumu": None,
                "ozel_not": None
            }

        messages = chat_log[client_id]["messages"]
        next_idx = str(max(map(int, messages.keys()), default=-1) + 1)

        # --- KullanÄ±cÄ± mesajÄ±nÄ± ekle
        messages[next_idx] = {
            "role": "user",
            "content": req_msg,
            "timestamp": datetime.now().isoformat()
        }
        
        all_keys = sorted(map(int, messages.keys()))
        if len(all_keys) > 50:
            to_delete = all_keys[:len(all_keys) - 50]
            for k in to_delete:
                del messages[str(k)]

        # --- Mesaj tipi
        msg_type = await mm.get_ai_response(
            req_msg, prompt=prompt["selection"]["product"]["tr"]
        )


        if chat_log[client_id]["state"]["son_intent"] == "fiyat_sordu":
            # KullanÄ±cÄ±nÄ±n son mesajÄ± Ã¼rÃ¼nle ilgili mi?
            resp = await client.embeddings.create(model="text-embedding-3-small", input=req_msg)
            user_vec = np.array(resp.data[0].embedding, dtype=np.float32)

            best, best_score = None, -1.0
            with SessionLocal() as db:
                for p in db.query(Product).filter(Product.embedding.isnot(None)):
                    prod_vec = np.frombuffer(p.embedding, dtype=np.float32)
                    sim = cosine(user_vec, prod_vec)
                    if sim > best_score:
                        best, best_score = p, sim

            if best_score > 0.80:
                chat_log[client_id]["state"]["son_urun"] = best.name

                # AÃ§Ä±klamadan fiyat belirleyici Ã¶zellikleri GPT ile Ã§Ä±kar
                prompt_text = (
                    f"AÅŸaÄŸÄ±da bir Ã¼rÃ¼n aÃ§Ä±klamasÄ± var. Bu aÃ§Ä±klamaya gÃ¶re Ã¼rÃ¼nÃ¼n fiyatÄ±nÄ± etkileyen "
                    f"Ã¶zellikleri kÄ±sa ve maddeler halinde belirt:\n\n"
                    f"\"\"\"\n{best.description}\n\"\"\"\n\n"
                    f"Sadece madde madde listele, Ã¶rnek: boyut, baskÄ± tipi, Ä±ÅŸÄ±k vs."
                )

                gpt_resp = await mm.get_ai_response("", prompt=prompt_text)
                Ã¶zellikler = gpt_resp.strip().replace("*", "ğŸ‘‰").replace("-", "ğŸ‘‰")

                bot_reply = (
                    f"<b>{best.name}</b> adlÄ± Ã¼rÃ¼n iÃ§in fiyat bilgisi verebilmem iÃ§in lÃ¼tfen aÅŸaÄŸÄ±daki Ã¶zellikleri belirtin:\n"
                    f"{Ã¶zellikler}\n\n"
                    f"ÃœrÃ¼nÃ¼ incelemek isterseniz: <a href='{best.permalink}'>{best.permalink}</a>"
                )
            else:
                chat_log[client_id]["state"]["son_intent"] = "Ã¼rÃ¼n_isteÄŸi"
                bot_reply = (
                    "Yeni bir Ã¼rÃ¼n istiyor gibisiniz. Hemen yardÄ±mcÄ± oluyorum.\n"
                    "Hangi Ã¼rÃ¼nÃ¼ aradÄ±ÄŸÄ±nÄ±zÄ± belirtir misiniz?"
                )

        # --- Ä°lgili iÅŸlemi yap
        elif msg_type == "Ã¼rÃ¼n_isteÄŸi":
            if len(req_msg.split()) <= 3:
                req_msg = f"{req_msg} Ã¼rÃ¼nÃ¼ almak istiyorum"

            resp = await client.embeddings.create(
                model="text-embedding-3-small",
                input=req_msg
            )
            user_vec = np.array(resp.data[0].embedding, dtype=np.float32)

            similar_products = []
            with SessionLocal() as db:
                for p in db.query(Product).filter(Product.embedding.isnot(None)):
                    prod_vec = np.frombuffer(p.embedding, dtype=np.float32)
                    sim = cosine(user_vec, prod_vec)
                    if sim > 0.80:  # EÅŸik deÄŸeri
                        similar_products.append((p, sim))

            similar_products.sort(key=lambda x: x[1], reverse=True)

            if similar_products:
                best = similar_products[0][0]
                listed = ""
                for p, score in similar_products:
                    listed += f"ğŸ”¹ <a href='{p.permalink}'>{p.name}</a>\n"

                bot_reply = (
                    f"Size en uygun Ã¼rÃ¼n: <b>{best.name}</b>\n"
                    f"Ä°ncelemek iÃ§in: <a href='{best.permalink}'>{best.permalink}</a>\n\n"
                    f"Benzer diÄŸer Ã¼rÃ¼nler:\n{listed.strip()}\n\n"
                    "Bu Ã¼rÃ¼nlerden hangisiyle ilgileniyorsunuz?"
                )
            else:
                bot_reply = "ÃœzgÃ¼nÃ¼m, benzer bir Ã¼rÃ¼n bulamadÄ±m. Daha fazla bilgi verebilir misiniz?"


        elif msg_type == "tasarÄ±m_isteÄŸi":
            # --- HafÄ±za: Son 10 mesajÄ± topla
            all_msgs = chat_log[client_id]["messages"]
            sorted_keys = sorted(map(int, all_msgs.keys()))
            recent_msgs = sorted_keys[-10:]

            history_text = ""
            for key in recent_msgs:
                m = all_msgs[str(key)]
                who = "KullanÄ±cÄ±" if m["role"] == "user" else "Bot"
                history_text += f"{who}: {m['content']}\n"

            # --- Embedding oluÅŸtur
            enriched_input = f"{history_text.strip()}\nSon mesaj: {req_msg}"
            resp = await client.embeddings.create(
                model="text-embedding-3-small",
                input=enriched_input
            )
            user_vec = np.array(resp.data[0].embedding, dtype=np.float32)

            # --- En uygun Ã¼rÃ¼nÃ¼ bul
            best, best_score = None, -1.0
            with SessionLocal() as db:
                for p in db.query(Product).filter(Product.embedding.isnot(None)):
                    prod_vec = np.frombuffer(p.embedding, dtype=np.float32)
                    sim = cosine(user_vec, prod_vec)
                    if sim > best_score:
                        best, best_score = p, sim

            # --- Model yanÄ±tÄ± oluÅŸtur
            if best:
                prompt_text = (
                    "AÅŸaÄŸÄ±da bir mÃ¼ÅŸterinin son konuÅŸmalarÄ± ve tasarÄ±m isteÄŸi yer almaktadÄ±r.\n"
                    "AyrÄ±ca Ã¼rÃ¼nlerimizden biri olan aÅŸaÄŸÄ±daki aÃ§Ä±klamayÄ± da gÃ¶z Ã¶nÃ¼nde bulundurarak, mÃ¼ÅŸterinin ihtiyacÄ±na en uygun Ã§Ã¶zÃ¼mÃ¼ Ã¶ner.\n\n"
                    f"KullanÄ±cÄ± konuÅŸma geÃ§miÅŸi:\n{history_text.strip()}\n\n"
                    f"TasarÄ±m isteÄŸi:\n{req_msg}\n\n"
                    f"Ä°lgili Ã¼rÃ¼n aÃ§Ä±klamasÄ±:\n{best.description}\n\n"
                    "YanÄ±t:"
                )

                bot_reply = await mm.get_ai_response(req_msg, prompt=prompt_text)
            else:
                bot_reply = "TasarÄ±m isteÄŸinizi anladÄ±m, ancak ÅŸu anda size uygun bir Ã¼rÃ¼n belirleyemedim. Daha fazla detay verebilir misiniz?"

        elif msg_type == "fiyat_sorgusu":
            chat_log[client_id]["state"]["son_intent"] = "fiyat_sordu"
            # --- Embedding oluÅŸtur (sadece son kullanÄ±cÄ± mesajÄ±)
            resp = await client.embeddings.create(
                model="text-embedding-3-small",
                input=req_msg
            )
            user_vec = np.array(resp.data[0].embedding, dtype=np.float32)

            # --- Benzer Ã¼rÃ¼nleri topla
            similar_products = []
            with SessionLocal() as db:
                for p in db.query(Product).filter(Product.embedding.isnot(None)):
                    prod_vec = np.frombuffer(p.embedding, dtype=np.float32)
                    sim = cosine(user_vec, prod_vec)
                    if sim > 0.80:  # Benzerlik eÅŸiÄŸi
                        similar_products.append((p, sim))

            similar_products.sort(key=lambda x: x[1], reverse=True)

            if len(similar_products) == 1:
                product = similar_products[0][0]
                bot_reply = (
                    f"Ä°lgili Ã¼rÃ¼n: <b>{product.name}</b>\n"
                    f"{product.summary or product.description}\n"
                    f"<a href='{product.permalink}' target='_blank'>ÃœrÃ¼nÃ¼ incele</a>\n\n"
                    "Dilerseniz detaylÄ± bilgi iÃ§in bizimle iletiÅŸime geÃ§ebilirsiniz:\n"
                    "ğŸ“ <a href='tel:+905356647752'>+90 535 664 77 52</a>\n"
                    "ğŸ“ <a href='tel:+902163790708'>+90 216 379 07 08</a>"
                )
            elif len(similar_products) > 1:
                listed = ""
                for p, score in similar_products:
                    listed += f"ğŸ”¹ <a href='{p.permalink}'>{p.name}</a>\n"

                bot_reply = (
                    "AÅŸaÄŸÄ±daki Ã¼rÃ¼nler sorunuza benzer olarak bulundu:\n\n"
                    f"{listed.strip()}\n\n"
                    "Bu Ã¼rÃ¼nlerden hangisiyle ilgileniyorsunuz? Daha net yardÄ±mcÄ± olabilirim."
                )
            else:
                bot_reply = (
                    "Ä°lgili Ã¼rÃ¼n ÅŸu anda veri tabanÄ±mÄ±zda gÃ¶rÃ¼nmÃ¼yor. "
                    "LÃ¼tfen daha fazla detay verebilir misiniz?"
                )
            


        elif msg_type == "mÃ¼ÅŸteri_temsili":
            bot_reply = (
                "Bize doÄŸrudan ulaÅŸmak isterseniz aÅŸaÄŸÄ±daki numaralardan bize ulaÅŸabilirsiniz:\n"
                "ğŸ“ <a href='tel:+905356647752'>+90 535 664 77 52</a>\n"
                "ğŸ“ <a href='tel:+902163790708'>+90 216 379 07 08</a>"
            )

        elif msg_type == "Ã¶rnek_istemi":
            bot_reply = (
                "Ã–nceki iÅŸlerimizi incelemek isterseniz Ã¶rnek projelerimize gÃ¶z atabilirsiniz:\n"
                "<a href='https://eymenreklam.com/%C3%BCr%C3%BCn-kategori/projeler/' target='_blank'>eymenreklam.com/projeler</a>"
            )

        elif msg_type == "hizmet_Ã¶grenme":
            # 1. Embedding oluÅŸtur
            resp = await client.embeddings.create(
                model="text-embedding-3-small",
                input=req_msg
            )
            user_vec = np.array(resp.data[0].embedding, dtype=np.float32)

            # 2. En yakÄ±n Ã¼rÃ¼nÃ¼ bul (isim Ã¼zerinden)
            best, best_score = None, -1.0
            with SessionLocal() as db:
                for p in db.query(Product).filter(Product.embedding.isnot(None)):
                    prod_vec = np.frombuffer(p.embedding, dtype=np.float32)
                    sim = cosine(user_vec, prod_vec)
                    if sim > best_score:
                        best, best_score = p, sim

            # 3. Uygun Ã¼rÃ¼n bulunduysa modelden detaylÄ± aÃ§Ä±klama iste
            if best:
                prompt_text = (
                    "AÅŸaÄŸÄ±da bir mÃ¼ÅŸteri mesajÄ± ve ona uygun Ã¼rÃ¼nÃ¼n aÃ§Ä±klamasÄ± verilmiÅŸtir.\n"
                    "MÃ¼ÅŸterinin ne istediÄŸini Ã¼rÃ¼n bilgisine gÃ¶re deÄŸerlendir ve aÃ§Ä±klayÄ±cÄ±, ikna edici bir yanÄ±t ver.\n\n"
                    f"MÃ¼ÅŸteri mesajÄ±:\n{req_msg}\n\n"
                    f"ÃœrÃ¼n aÃ§Ä±klamasÄ±:\n{best.description}\n\n"
                    "YanÄ±t:"
                )

                bot_reply = await mm.get_ai_response(req_msg, prompt=prompt_text)
            else:
                bot_reply = "Åu an iÃ§in ilgili hizmete dair bir Ã¼rÃ¼n bulamadÄ±m. Hangi konuda bilgi almak istediÄŸinizi detaylandÄ±rabilir misiniz?"


        elif msg_type == "sohbet":
            all_msgs = chat_log[client_id]["messages"]
            sorted_keys = sorted(map(int, all_msgs.keys()))
            recent_msgs = sorted_keys[-10:]

            history_text = ""
            for key in recent_msgs:
                m = all_msgs[str(key)]
                who = "KullanÄ±cÄ±" if m["role"] == "user" else "Bot"
                history_text += f"{who}: {m['content']}\n"

            prompt_text = prompt["chat"]["connect"]["tr"].replace("{}", history_text.strip())
            bot_reply = await mm.get_ai_response(req_msg, prompt=prompt_text)

        else:
            bot_reply = "MesajÄ±nÄ±zÄ± tam anlayamadÄ±m. Ne hakkÄ±nda konuÅŸmak istersiniz?"

        # --- Bot mesajÄ±nÄ± ekle
        messages[str(int(next_idx) + 1)] = {
            "role": "bot",
            "content": bot_reply,
            "timestamp": datetime.now().isoformat()
        }

        # --- GÃ¼ncel logu kaydet
        with open(LOG_FILE, "w", encoding="utf-8") as f:
            json.dump(chat_log, f, ensure_ascii=False, indent=2)

        return {"reply": bot_reply}

    except Exception as e:
        import traceback
        print("âŒ chat_handler hatasÄ±:")
        traceback.print_exc()

        raise HTTPException(
            status_code=500,
            detail="Sunucuda beklenmeyen bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar deneyin."
        )
