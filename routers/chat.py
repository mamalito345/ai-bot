from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from models import model_main as mm
from database.db import SessionLocal
from models.db_models import Product
import numpy as np
from numpy.linalg import norm
from openai import AsyncOpenAI
import json, asyncio
from datetime import datetime
import os

# -------------------------------------------------
with open("prompt.json", "r", encoding="utf-8") as f:
    prompt = json.load(f)

LOG_FILE = "chat_log.json"

# Ä°lk baÅŸta dosya yoksa oluÅŸtur
if not os.path.exists(LOG_FILE):
    with open(LOG_FILE, "w", encoding="utf-8") as f:
        json.dump({}, f)

router = APIRouter()
client = AsyncOpenAI()

class ChatRequest(BaseModel):
    message: str
    client_id: str

class ChatResponse(BaseModel):
    reply: str

def cosine(a: np.ndarray, b: np.ndarray) -> float:
    return float(np.dot(a, b) / (norm(a) * norm(b)))

# -------------------------------------------------
@router.post("/chat", response_model=ChatResponse)
async def chat_handler(payload: ChatRequest):
    try:
        req_msg   = payload.message.strip()
        client_id = payload.client_id.strip()

        # --- Log dosyasÄ±nÄ± oku
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            chat_log = json.load(f)

        if client_id not in chat_log:
            chat_log[client_id] = {"messages": {}}

        messages = chat_log[client_id]["messages"]
        next_idx = str(max(map(int, messages.keys()), default=-1) + 1)

        # --- KullanÄ±cÄ± mesajÄ±nÄ± ekle
        messages[next_idx] = {
            "role": "user",
            "content": req_msg,
            "timestamp": datetime.now().isoformat()
        }
        
        all_keys = sorted(map(int, messages.keys()))
        if len(all_keys) > 50:
            to_delete = all_keys[:len(all_keys) - 50]
            for k in to_delete:
                del messages[str(k)]

        # --- Mesaj tipi
        msg_type = await mm.get_ai_response(
            req_msg, prompt=prompt["selection"]["product"]["tr"]
        )



        # --- Ä°lgili iÅŸlemi yap
        if msg_type == "Ã¼rÃ¼n_isteÄŸi":
            if len(req_msg.split()) <= 3:
                req_msg = f"{req_msg} Ã¼rÃ¼nÃ¼ almak istiyorum"

            resp = await client.embeddings.create(
                model="text-embedding-3-small",
                input=req_msg
            )
            user_vec = np.array(resp.data[0].embedding, dtype=np.float32)

            best, best_score = None, -1.0
            with SessionLocal() as db:
                for p in db.query(Product).filter(Product.embedding.isnot(None)):
                    prod_vec = np.frombuffer(p.embedding, dtype=np.float32)
                    sim = cosine(user_vec, prod_vec)
                    if sim > best_score:
                        best, best_score = p, sim

            if best:
                bot_reply = f"Size en uygun Ã¼rÃ¼n: {best.name}\nÄ°ncelemek iÃ§in: {best.permalink}"
            else:
                bot_reply = "ÃœzgÃ¼nÃ¼m, benzer bir Ã¼rÃ¼n bulamadÄ±m."

        elif msg_type == "tasarÄ±m_isteÄŸi":
            # --- HafÄ±za: Son 10 mesajÄ± topla
            all_msgs = chat_log[client_id]["messages"]
            sorted_keys = sorted(map(int, all_msgs.keys()))
            recent_msgs = sorted_keys[-10:]

            history_text = ""
            for key in recent_msgs:
                m = all_msgs[str(key)]
                who = "KullanÄ±cÄ±" if m["role"] == "user" else "Bot"
                history_text += f"{who}: {m['content']}\n"

            # --- Embedding oluÅŸtur
            enriched_input = f"{history_text.strip()}\nSon mesaj: {req_msg}"
            resp = await client.embeddings.create(
                model="text-embedding-3-small",
                input=enriched_input
            )
            user_vec = np.array(resp.data[0].embedding, dtype=np.float32)

            # --- En uygun Ã¼rÃ¼nÃ¼ bul
            best, best_score = None, -1.0
            with SessionLocal() as db:
                for p in db.query(Product).filter(Product.embedding.isnot(None)):
                    prod_vec = np.frombuffer(p.embedding, dtype=np.float32)
                    sim = cosine(user_vec, prod_vec)
                    if sim > best_score:
                        best, best_score = p, sim

            # --- Model yanÄ±tÄ± oluÅŸtur
            if best:
                prompt_text = (
                    "AÅŸaÄŸÄ±da bir mÃ¼ÅŸterinin son konuÅŸmalarÄ± ve tasarÄ±m isteÄŸi yer almaktadÄ±r.\n"
                    "AyrÄ±ca Ã¼rÃ¼nlerimizden biri olan aÅŸaÄŸÄ±daki aÃ§Ä±klamayÄ± da gÃ¶z Ã¶nÃ¼nde bulundurarak, mÃ¼ÅŸterinin ihtiyacÄ±na en uygun Ã§Ã¶zÃ¼mÃ¼ Ã¶ner.\n\n"
                    f"KullanÄ±cÄ± konuÅŸma geÃ§miÅŸi:\n{history_text.strip()}\n\n"
                    f"TasarÄ±m isteÄŸi:\n{req_msg}\n\n"
                    f"Ä°lgili Ã¼rÃ¼n aÃ§Ä±klamasÄ±:\n{best.description}\n\n"
                    "YanÄ±t:"
                )

                bot_reply = await mm.get_ai_response(req_msg, prompt=prompt_text)
            else:
                bot_reply = "TasarÄ±m isteÄŸinizi anladÄ±m, ancak ÅŸu anda size uygun bir Ã¼rÃ¼n belirleyemedim. Daha fazla detay verebilir misiniz?"

        elif msg_type == "fiyat_sorgusu":
            bot_reply = (
                "Dilerseniz daha detaylÄ± bilgi iÃ§in bizimle iletiÅŸime geÃ§ebilirsiniz:\n"
                "ğŸ“ <a href='tel:+905356647752'>+90 535 664 77 52</a>\n"
                "ğŸ“ <a href='tel:+902163790708'>+90 216 379 07 08</a>"
            )


        elif msg_type == "stok_sorgusu":
            bot_reply = await mm.get_ai_response(
            req_msg, prompt=prompt["selection"]["stok_sorgusu"]["tr"]
        )

        elif msg_type == "teslimat_sorgusu":
            bot_reply = (
                "Ãœretim sÃ¼reÃ§leri ve teslimat bilgisi iÃ§in lÃ¼tfen bize ulaÅŸÄ±n!\n"
                "ğŸ“ <a href='tel:+905356647752'>+90 535 664 77 52</a>\n"
                "ğŸ“ <a href='tel:+902163790708'>+90 216 379 07 08</a>"
            )
        elif msg_type == "kargo":
            bot_reply = (
                "Ãœretim sÃ¼reÃ§leri ve teslimat bilgisi iÃ§in lÃ¼tfen bize ulaÅŸÄ±n!\n"
                "ğŸ“ <a href='tel:+905356647752'>+90 535 664 77 52</a>\n"
                "ğŸ“ <a href='tel:+902163790708'>+90 216 379 07 08</a>"
            )

        elif msg_type == "destek_talebi":
            bot_reply = (
                "Bize doÄŸrudan ulaÅŸmak isterseniz aÅŸaÄŸÄ±daki numaralardan bize ulaÅŸabilirsiniz:\n"
                "ğŸ“ <a href='tel:+905356647752'>+90 535 664 77 52</a>\n"
                "ğŸ“ <a href='tel:+902163790708'>+90 216 379 07 08</a>"
            )

        elif msg_type == "mÃ¼ÅŸteri_temsili":
            bot_reply = (
                "Bize doÄŸrudan ulaÅŸmak isterseniz aÅŸaÄŸÄ±daki numaralardan bize ulaÅŸabilirsiniz:\n"
                "ğŸ“ <a href='tel:+905356647752'>+90 535 664 77 52</a>\n"
                "ğŸ“ <a href='tel:+902163790708'>+90 216 379 07 08</a>"
            )

        elif msg_type == "Ã¶rnek_istemi":
            bot_reply = (
                "Ã–nceki iÅŸlerimizi incelemek isterseniz Ã¶rnek projelerimize gÃ¶z atabilirsiniz:\n"
                "<a href='https://eymenreklam.com/%C3%BCr%C3%BCn-kategori/projeler/' target='_blank'>eymenreklam.com/projeler</a>"
            )

        elif msg_type == "hizmet_Ã¶grenme":
            # 1. Embedding oluÅŸtur
            resp = await client.embeddings.create(
                model="text-embedding-3-small",
                input=req_msg
            )
            user_vec = np.array(resp.data[0].embedding, dtype=np.float32)

            # 2. En yakÄ±n Ã¼rÃ¼nÃ¼ bul (isim Ã¼zerinden)
            best, best_score = None, -1.0
            with SessionLocal() as db:
                for p in db.query(Product).filter(Product.embedding.isnot(None)):
                    prod_vec = np.frombuffer(p.embedding, dtype=np.float32)
                    sim = cosine(user_vec, prod_vec)
                    if sim > best_score:
                        best, best_score = p, sim

            # 3. Uygun Ã¼rÃ¼n bulunduysa modelden detaylÄ± aÃ§Ä±klama iste
            if best:
                prompt_text = (
                    "AÅŸaÄŸÄ±da bir mÃ¼ÅŸteri mesajÄ± ve ona uygun Ã¼rÃ¼nÃ¼n aÃ§Ä±klamasÄ± verilmiÅŸtir.\n"
                    "MÃ¼ÅŸterinin ne istediÄŸini Ã¼rÃ¼n bilgisine gÃ¶re deÄŸerlendir ve aÃ§Ä±klayÄ±cÄ±, ikna edici bir yanÄ±t ver.\n\n"
                    f"MÃ¼ÅŸteri mesajÄ±:\n{req_msg}\n\n"
                    f"ÃœrÃ¼n aÃ§Ä±klamasÄ±:\n{best.description}\n\n"
                    "YanÄ±t:"
                )

                bot_reply = await mm.get_ai_response(req_msg, prompt=prompt_text)
            else:
                bot_reply = "Åu an iÃ§in ilgili hizmete dair bir Ã¼rÃ¼n bulamadÄ±m. Hangi konuda bilgi almak istediÄŸinizi detaylandÄ±rabilir misiniz?"


        elif msg_type == "sohbet":
            all_msgs = chat_log[client_id]["messages"]
            sorted_keys = sorted(map(int, all_msgs.keys()))
            recent_msgs = sorted_keys[-10:]

            history_text = ""
            for key in recent_msgs:
                m = all_msgs[str(key)]
                who = "KullanÄ±cÄ±" if m["role"] == "user" else "Bot"
                history_text += f"{who}: {m['content']}\n"

            prompt_text = prompt["chat"]["connect"]["tr"].replace("{}", history_text.strip())
            bot_reply = await mm.get_ai_response(req_msg, prompt=prompt_text)

        else:
            bot_reply = "MesajÄ±nÄ±zÄ± tam anlayamadÄ±m. Ne hakkÄ±nda konuÅŸmak istersiniz?"

        # --- Bot mesajÄ±nÄ± ekle
        messages[str(int(next_idx) + 1)] = {
            "role": "bot",
            "content": bot_reply,
            "timestamp": datetime.now().isoformat()
        }

        # --- GÃ¼ncel logu kaydet
        with open(LOG_FILE, "w", encoding="utf-8") as f:
            json.dump(chat_log, f, ensure_ascii=False, indent=2)

        return {"reply": bot_reply}

    except Exception as e:
        import traceback
        print("âŒ chat_handler hatasÄ±:")
        traceback.print_exc()

        raise HTTPException(
            status_code=500,
            detail="Sunucuda beklenmeyen bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar deneyin."
        )
